{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytrends.request import TrendReq\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "country_df = pd.read_csv('../country.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = [\"United States\", \"China\", \"France\", \"Ukraine\", \"Russia\"] # country_df['name'].sample(5).to_list()\n",
    "payload = pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='US', gprop='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pytrends.interest_over_time()[kw_list]\n",
    "series[kw_list] = MinMaxScaler().fit_transform(series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_graph_seq2seq_io_data(\n",
    "        df, x_offsets, y_offsets\n",
    "):\n",
    "    num_samples, num_nodes = df.shape\n",
    "    data = np.expand_dims(df.values, axis=-1)\n",
    "    # epoch_len = num_samples + min(x_offsets) - max(y_offsets)\n",
    "    x, y = [], []\n",
    "    # t is the index of the last observation.\n",
    "    min_t = abs(min(x_offsets))\n",
    "    max_t = abs(num_samples - abs(max(y_offsets)))  # Exclusive\n",
    "    for t in range(min_t, max_t):\n",
    "        x_t = data[t + x_offsets, ...]\n",
    "        y_t = data[t + y_offsets, ...]\n",
    "        x.append(x_t)\n",
    "        y.append(y_t)\n",
    "    x = np.stack(x, axis=0)\n",
    "    y = np.stack(y, axis=0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(df, input_length, output_length):\n",
    "\n",
    "    x_offsets = np.sort(\n",
    "            np.concatenate((np.arange(-input_length, 1, 1),))\n",
    "        )\n",
    "    y_offsets = np.sort(np.arange(1, output_length, 1))\n",
    "\n",
    "    x, y = generate_graph_seq2seq_io_data(\n",
    "        df,\n",
    "        x_offsets=x_offsets,\n",
    "        y_offsets=y_offsets,\n",
    "        # add_time_in_day=True,\n",
    "        # add_day_in_week=False,\n",
    "    )\n",
    "\n",
    "    print(\"x shape: \", x.shape, \", y shape: \", y.shape)\n",
    "    # Write the data into npz file.\n",
    "    # num_test = 6831, using the last 6831 examples as testing.\n",
    "    # for the rest: 7/8 is used for training, and 1/8 is used for validation.\n",
    "    num_samples = x.shape[0]\n",
    "    num_test = round(num_samples * 0.2)\n",
    "    num_train = round(num_samples * 0.7)\n",
    "    num_val = num_samples - num_test - num_train\n",
    "\n",
    "    # train\n",
    "    x_train, y_train = x[:num_train], y[:num_train]\n",
    "    # val\n",
    "    x_val, y_val = (\n",
    "        x[num_train: num_train + num_val],\n",
    "        y[num_train: num_train + num_val],\n",
    "    )\n",
    "    # test\n",
    "    x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (241, 11, 5, 1) , y shape:  (241, 9, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = generate_train_val_test(series, 10, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric_temporal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m MTGNN\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m MTGNN(\n\u001b[0;32m      4\u001b[0m     gcn_true\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      5\u001b[0m     build_adj\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m     gcn_depth\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m     num_nodes\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     seq_length\u001b[39m=\u001b[39;49mx_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m      9\u001b[0m     kernel_set\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[0;32m     10\u001b[0m     kernel_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[0;32m     11\u001b[0m     dropout\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m, \n\u001b[0;32m     12\u001b[0m     subgraph_size\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, \n\u001b[0;32m     13\u001b[0m     node_dim\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, \n\u001b[0;32m     14\u001b[0m     dilation_exponential\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[0;32m     15\u001b[0m     conv_channels\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, \n\u001b[0;32m     16\u001b[0m     residual_channels\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, \n\u001b[0;32m     17\u001b[0m     skip_channels\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, \n\u001b[0;32m     18\u001b[0m     end_channels\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, \n\u001b[0;32m     19\u001b[0m     in_dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m     20\u001b[0m     out_dim\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m, \n\u001b[0;32m     21\u001b[0m     layers\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, \n\u001b[0;32m     22\u001b[0m     propalpha\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m, \n\u001b[0;32m     23\u001b[0m     tanhalpha\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     24\u001b[0m     layer_norm_affline\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\simon\\Projets\\CountryTrends\\.conda\\lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:528\u001b[0m, in \u001b[0;36mMTGNN.__init__\u001b[1;34m(self, gcn_true, build_adj, gcn_depth, num_nodes, kernel_set, kernel_size, dropout, subgraph_size, node_dim, dilation_exponential, conv_channels, residual_channels, skip_channels, end_channels, seq_length, in_dim, out_dim, layers, propalpha, tanhalpha, layer_norm_affline, xd)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mtgnn_layers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList()\n\u001b[0;32m    524\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_constructor \u001b[39m=\u001b[39m GraphConstructor(\n\u001b[0;32m    525\u001b[0m     num_nodes, subgraph_size, node_dim, alpha\u001b[39m=\u001b[39mtanhalpha, xd\u001b[39m=\u001b[39mxd\n\u001b[0;32m    526\u001b[0m )\n\u001b[1;32m--> 528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_receptive_field(dilation_exponential, kernel_size, layers)\n\u001b[0;32m    530\u001b[0m new_dilation \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    531\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, layers \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\simon\\Projets\\CountryTrends\\.conda\\lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:631\u001b[0m, in \u001b[0;36mMTGNN._set_receptive_field\u001b[1;34m(self, dilation_exponential, kernel_size, layers)\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_receptive_field \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\n\u001b[0;32m    625\u001b[0m         \u001b[39m1\u001b[39m\n\u001b[0;32m    626\u001b[0m         \u001b[39m+\u001b[39m (kernel_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    627\u001b[0m         \u001b[39m*\u001b[39m (dilation_exponential \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m layers \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    628\u001b[0m         \u001b[39m/\u001b[39m (dilation_exponential \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_receptive_field \u001b[39m=\u001b[39m layers \u001b[39m*\u001b[39m (kernel_size \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn import MTGNN\n",
    "\n",
    "model = MTGNN(\n",
    "    gcn_true=True,\n",
    "    build_adj=True,\n",
    "    gcn_depth=2,\n",
    "    num_nodes=5,\n",
    "    seq_length=x_train.shape[1],\n",
    "    kernel_set=None, \n",
    "    kernel_size=None, \n",
    "    dropout=0.3, \n",
    "    subgraph_size=20, \n",
    "    node_dim=40, \n",
    "    dilation_exponential=1, \n",
    "    conv_channels=32, \n",
    "    residual_channels=32, \n",
    "    skip_channels=64, \n",
    "    end_channels=128, \n",
    "    in_dim=2, \n",
    "    out_dim=12, \n",
    "    layers=3, \n",
    "    propalpha=0.05, \n",
    "    tanhalpha=3,\n",
    "    layer_norm_affline=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "num_nodes = x_train.shape[-2]\n",
    "gcn_true = True\n",
    "buildA_true = True #We want to build the Adjacency matrix.\n",
    "gcn_depth = 8\n",
    "seq_length = x_train.shape[1]\n",
    "model = gtnet(buildA_true=buildA_true, gcn_true=gcn_true, gcn_depth=gcn_depth, num_nodes=num_nodes, device=device, seq_length=seq_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 11, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = torch.tensor(x_train[0]).unsqueeze(0).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_conv = nn.Conv2d(in_channels=2,\n",
    "                                    out_channels=12,\n",
    "                                    kernel_size=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0870],\n",
       "          [0.0870],\n",
       "          [0.0870],\n",
       "          [0.0870],\n",
       "          [0.0870],\n",
       "          [0.0870],\n",
       "          [0.1304],\n",
       "          [0.1304],\n",
       "          [0.0870],\n",
       "          [0.0870],\n",
       "          [0.0870]],\n",
       "\n",
       "         [[0.0588],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.1176],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.0588],\n",
       "          [0.0000]],\n",
       "\n",
       "         [[0.0667],\n",
       "          [0.1333],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667],\n",
       "          [0.0667]],\n",
       "\n",
       "         [[0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000]],\n",
       "\n",
       "         [[0.0294],\n",
       "          [0.0147],\n",
       "          [0.0147],\n",
       "          [0.0147],\n",
       "          [0.0588],\n",
       "          [0.0441],\n",
       "          [0.0147],\n",
       "          [0.0147],\n",
       "          [0.0147],\n",
       "          [0.0147],\n",
       "          [0.0147]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_conv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
